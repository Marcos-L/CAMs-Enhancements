{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":2702213,"sourceType":"datasetVersion","datasetId":1645904},{"sourceId":2702226,"sourceType":"datasetVersion","datasetId":1269900},{"sourceId":5137200,"sourceType":"datasetVersion","datasetId":2984453},{"sourceId":5175158,"sourceType":"datasetVersion","datasetId":3008205}],"dockerImageVersionId":30302,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Download Packages","metadata":{"id":"x9LNzEYERaH2"}},{"cell_type":"code","source":"!nvidia-smi -L","metadata":{"execution":{"iopub.status.busy":"2024-10-22T19:31:22.637970Z","iopub.execute_input":"2024-10-22T19:31:22.638401Z","iopub.status.idle":"2024-10-22T19:31:23.744281Z","shell.execute_reply.started":"2024-10-22T19:31:22.638361Z","shell.execute_reply":"2024-10-22T19:31:23.742963Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"GPU 0: Tesla T4 (UUID: GPU-86163367-94e2-1d3b-ede1-17dd7215dbeb)\nGPU 1: Tesla T4 (UUID: GPU-ba3c2cc9-fb8b-d1fb-d06c-67d029b4b1d7)\n","output_type":"stream"}]},{"cell_type":"code","source":"%%capture\n!pip install -U git+https://github.com/UN-GCPDS/python-gcpds.databases #Package for database reading.\n!pip install mne #The MNE Package is installed\nFILEID = \"1lo0MjWLvsyne2CgTA6VZ2HGY9SKxiwZ7\"\n!wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id='$FILEID -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=\"$FILEID -O MI_EEG_ClassMeth.zip && rm -rf /tmp/cookies.txt\n!unzip MI_EEG_ClassMeth.zip #Package with useful functions for motor imagery classification based in EEG.\n!pip install -U git+https://github.com/UN-GCPDS/python-gcpds.EEG_Tensorflow_models.git\n!dir","metadata":{"id":"K0oS6IH7VTZX","execution":{"iopub.status.busy":"2024-07-11T00:56:33.041323Z","iopub.execute_input":"2024-07-11T00:56:33.042422Z","iopub.status.idle":"2024-07-11T00:58:46.379074Z","shell.execute_reply.started":"2024-07-11T00:56:33.042279Z","shell.execute_reply":"2024-07-11T00:58:46.377383Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"!apt-get install --allow-change-held-packages libcudnn8=8.1.0.77-1+cuda11.2 -y\n!pip install tensorflow==2.8.2","metadata":{"execution":{"iopub.status.busy":"2024-07-11T00:58:46.381816Z","iopub.execute_input":"2024-07-11T00:58:46.382876Z","iopub.status.idle":"2024-07-11T00:59:55.125056Z","shell.execute_reply.started":"2024-07-11T00:58:46.382828Z","shell.execute_reply":"2024-07-11T00:59:55.123702Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Reading package lists... Done\nBuilding dependency tree       \nReading state information... Done\nE: Unable to locate package libcudnn8\nCollecting tensorflow==2.8.2\n  Downloading tensorflow-2.8.2-cp37-cp37m-manylinux2010_x86_64.whl (497.9 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m497.9/497.9 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: absl-py>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.8.2) (2.1.0)\nRequirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.8.2) (3.3.0)\nRequirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.8.2) (1.6.3)\nRequirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.8.2) (0.2.0)\nRequirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.8.2) (1.1.0)\nRequirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.8.2) (4.4.0)\nRequirement already satisfied: libclang>=9.0.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.8.2) (18.1.1)\nCollecting keras<2.9,>=2.8.0rc0\n  Downloading keras-2.8.0-py2.py3-none-any.whl (1.4 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m48.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: numpy>=1.20 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.8.2) (1.21.6)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.8.2) (59.8.0)\nCollecting tensorflow-estimator<2.9,>=2.8\n  Downloading tensorflow_estimator-2.8.0-py2.py3-none-any.whl (462 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m462.3/462.3 kB\u001b[0m \u001b[31m35.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: protobuf<3.20,>=3.9.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.8.2) (3.19.4)\nCollecting tensorboard<2.9,>=2.8\n  Downloading tensorboard-2.8.0-py3-none-any.whl (5.8 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m45.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n\u001b[?25hRequirement already satisfied: gast>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.8.2) (0.4.0)\nRequirement already satisfied: flatbuffers>=1.12 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.8.2) (24.3.25)\nRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.8.2) (0.34.0)\nRequirement already satisfied: keras-preprocessing>=1.1.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.8.2) (1.1.2)\nRequirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.8.2) (3.7.0)\nRequirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.8.2) (1.15.0)\nRequirement already satisfied: wrapt>=1.11.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.8.2) (1.12.1)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.8.2) (1.43.0)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.7/site-packages (from astunparse>=1.6.0->tensorflow==2.8.2) (0.37.1)\nRequirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.2) (0.6.1)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.2) (3.3.7)\nRequirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.2) (0.4.6)\nRequirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.2) (2.28.1)\nRequirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.2) (1.8.1)\nRequirement already satisfied: werkzeug>=0.11.15 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.2) (2.2.2)\nRequirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.2) (1.35.0)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8.2) (0.2.7)\nRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8.2) (4.8)\nRequirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8.2) (4.2.4)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow==2.8.2) (1.3.1)\nRequirement already satisfied: importlib-metadata>=4.4 in /opt/conda/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow==2.8.2) (4.13.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8.2) (3.3)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8.2) (2022.9.24)\nRequirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8.2) (2.1.0)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8.2) (1.26.12)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.7/site-packages (from werkzeug>=0.11.15->tensorboard<2.9,>=2.8->tensorflow==2.8.2) (2.1.1)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow==2.8.2) (3.8.0)\nRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8.2) (0.4.8)\nRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow==2.8.2) (3.2.0)\nInstalling collected packages: tensorflow-estimator, keras, tensorboard, tensorflow\n  Attempting uninstall: tensorflow-estimator\n    Found existing installation: tensorflow-estimator 2.11.0\n    Uninstalling tensorflow-estimator-2.11.0:\n      Successfully uninstalled tensorflow-estimator-2.11.0\n  Attempting uninstall: keras\n    Found existing installation: keras 2.11.0\n    Uninstalling keras-2.11.0:\n      Successfully uninstalled keras-2.11.0\n  Attempting uninstall: tensorboard\n    Found existing installation: tensorboard 2.11.2\n    Uninstalling tensorboard-2.11.2:\n      Successfully uninstalled tensorboard-2.11.2\n  Attempting uninstall: tensorflow\n    Found existing installation: tensorflow 2.11.0\n    Uninstalling tensorflow-2.11.0:\n      Successfully uninstalled tensorflow-2.11.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntfx-bsl 1.9.0 requires absl-py<2.0.0,>=0.9, but you have absl-py 2.1.0 which is incompatible.\ntfx-bsl 1.9.0 requires pyarrow<6,>=1, but you have pyarrow 8.0.0 which is incompatible.\ntfx-bsl 1.9.0 requires tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,<3,>=1.15.5, but you have tensorflow 2.8.2 which is incompatible.\ntensorflow-transform 1.9.0 requires absl-py<2.0.0,>=0.9, but you have absl-py 2.1.0 which is incompatible.\ntensorflow-transform 1.9.0 requires pyarrow<6,>=1, but you have pyarrow 8.0.0 which is incompatible.\ntensorflow-transform 1.9.0 requires tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,<2.10,>=1.15.5, but you have tensorflow 2.8.2 which is incompatible.\ntensorflow-serving-api 2.9.0 requires tensorflow<3,>=2.9.0, but you have tensorflow 2.8.2 which is incompatible.\ntensorflow-io 0.21.0 requires tensorflow<2.7.0,>=2.6.0, but you have tensorflow 2.8.2 which is incompatible.\ntensorflow-io 0.21.0 requires tensorflow-io-gcs-filesystem==0.21.0, but you have tensorflow-io-gcs-filesystem 0.34.0 which is incompatible.\npytorch-lightning 1.7.7 requires tensorboard>=2.9.1, but you have tensorboard 2.8.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed keras-2.8.0 tensorboard-2.8.0 tensorflow-2.8.2 tensorflow-estimator-2.8.0\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"markdown","source":"# Functions","metadata":{}},{"cell_type":"code","source":"from gcpds.databases.BCI_Competition_IV import Dataset_2a\nfrom typing import Sequence, Tuple\nfrom MI_EEG_ClassMeth.FeatExtraction import TimeFrequencyRpr\nimport numpy as np\nfrom scipy.signal import resample\n\ndef load_BCICIV2a(db: Dataset_2a,\n               sbj: int,\n               mode: str,\n               fs: float, \n               f_bank: np.ndarray, \n               vwt: np.ndarray, \n               new_fs: float) -> np.ndarray:\n\n  tf_repr = TimeFrequencyRpr(sfreq = fs, f_bank = f_bank, vwt = vwt)\n\n  db.load_subject(sbj, mode = mode)\n  X, y = db.get_data() #Load all classes, all channels {EEG, EOG}, reject bad trials\n  X = X[:,:-3,:] # pick EEG channels\n  X = X*1e6 #uV\n  X = np.squeeze(tf_repr.transform(X))\n  #Resampling\n  if new_fs == fs:\n    print('No resampling, since new sampling rate same.')\n  else:\n    print(\"Resampling from {:f} to {:f} Hz.\".format(fs, new_fs))\n    X = resample(X, int((X.shape[-1]/fs)*new_fs), axis = -1)\n    \n  return X, y\n\n\nfrom gcpds.databases import GIGA_MI_ME\n\ndef load_GIGA_MI_ME(db: GIGA_MI_ME,\n              sbj: int,\n              eeg_ch_names: Sequence[str],\n              fs: float, \n              f_bank: np.ndarray, \n              vwt: np.ndarray, \n              new_fs: float) -> Tuple[np.ndarray, np.ndarray]:\n\n  index_eeg_chs = db.format_channels_selectors(channels = eeg_ch_names) - 1\n\n  tf_repr = TimeFrequencyRpr(sfreq = fs, f_bank = f_bank, vwt = vwt)\n\n  db.load_subject(sbj)\n  X, y = db.get_data(classes = ['left hand mi', 'right hand mi']) #Load MI classes, all channels {EEG}, reject bad trials, uV\n  X = X[:, index_eeg_chs, :] #spatial rearrangement\n  X = np.squeeze(tf_repr.transform(X))\n  #Resampling\n  if new_fs == fs:\n    print('No resampling, since new sampling rate same.')\n  else:\n    print(\"Resampling from {:f} to {:f} Hz.\".format(fs, new_fs))\n    X = resample(X, int((X.shape[-1]/fs)*new_fs), axis = -1)\n    \n  return X, y\n\n\ndef load_DB(db_name, **load_args):\n  if db_name == 'BCICIV2a':\n    X_train, y_train = load_BCICIV2a(**load_args, mode = 'training')\n    X_test, y_test = load_BCICIV2a(**load_args, mode = 'evaluation')\n\n    X_train = np.concatenate([X_train, X_test], axis = 0)\n    y_train = np.concatenate([y_train, y_test], axis = 0)\n\n  elif db_name == 'GIGA_MI_ME':\n    X_train, y_train = load_GIGA_MI_ME(**load_args)\n\n  else:\n    raise ValueError('No valid database name')\n\n  return X_train, y_train\n\n\nfrom EEG_Tensorflow_models.Models import DeepConvNet, ShallowConvNet, EEGNet, DMTL_BCI, TCNet_fusion, PST_attention\n\n\ndef get_model(model_name, nb_classes):\n  if model_name == 'DeepConvNet':\n    model = DeepConvNet\n    model_params = dict(nb_classes = nb_classes,\n                      dropoutRate = 0.5, version='2018')\n    \n  elif model_name == 'ShallowConvNet':\n    model = ShallowConvNet\n    model_params = dict(nb_classes = nb_classes,\n                      dropoutRate = 0.5,\n                      version = '2018')\n    \n  elif model_name == 'EEGNet':\n    model = EEGNet\n    model_params = dict(nb_classes = nb_classes,\n                      dropoutRate = 0.5,\n                      kernLength = 32,\n                      F1 = 8,\n                      D = 2,\n                      F2 = 16,\n                      norm_rate = 0.25,\n                      dropoutType = 'Dropout')\n    \n  elif model_name == 'DMTL_BCI':\n    model = DMTL_BCI\n    model_params = dict(nb_classes = nb_classes,\n                      dropoutRate = 0.5,\n                      l1 = 0,\n                      l2 = 0)\n    \n  elif model_name == 'TCNet_fusion':\n    model = TCNet_fusion\n    model_params = dict(nb_classes = nb_classes,\n                      layers = 2,\n                      kernel_s = 4,\n                      filt = 12,\n                      dropout = 0.3,\n                      activation = 'relu',\n                      F1 = 24,\n                      D = 2,\n                      kernLength = 32,\n                      N_residuals = 2)\n    \n  elif model_name == 'PST_attention':\n    model = PST_attention\n    model_params = dict(nb_classes = nb_classes,\n                      dropoutRate = 0.5,\n                      last_layer = 'Dense')\n    \n  else:\n    raise ValueError('No valid model name')\n    \n  return model, model_params\n\nfrom tensorflow.random import set_seed\nfrom tensorflow.keras.backend import clear_session\nfrom tensorflow.keras.optimizers import Adam\nfrom sklearn.metrics import accuracy_score, cohen_kappa_score, roc_auc_score,\\\n                            f1_score, recall_score, precision_score\n\ndef train(db_name, load_args, cv_args, model_args, compile_args, fit_args, seed):\n    X_train, y_train = load_DB(db_name, **load_args)\n    X_train = X_train[..., np.newaxis]\n    \n    cv_results = {'params': [],\n                  'mean_acc': np.zeros(cv_args['cv'].get_n_splits()),\n                  'mean_kappa': np.zeros(cv_args['cv'].get_n_splits()),\n                  'mean_auc': np.zeros(cv_args['cv'].get_n_splits()),\n                  'mean_f1_left': np.zeros(cv_args['cv'].get_n_splits()),\n                  'mean_f1_right': np.zeros(cv_args['cv'].get_n_splits()),\n                  'mean_recall_left': np.zeros(cv_args['cv'].get_n_splits()),\n                  'mean_recall_right': np.zeros(cv_args['cv'].get_n_splits()),\n                  'mean_precision_left': np.zeros(cv_args['cv'].get_n_splits()),\n                  'mean_precision_right': np.zeros(cv_args['cv'].get_n_splits()),}\n    \n    if model_args['nb_classes'] == 4:\n        cv_results['mean_f1_legs'] = np.zeros(cv_args['cv'].get_n_splits())\n        cv_results['mean_f1_tongue'] = np.zeros(cv_args['cv'].get_n_splits())\n        cv_results['mean_recall_legs'] = np.zeros(cv_args['cv'].get_n_splits())\n        cv_results['mean_recall_tongue'] = np.zeros(cv_args['cv'].get_n_splits())\n        cv_results['mean_precision_legs'] = np.zeros(cv_args['cv'].get_n_splits())\n        cv_results['mean_precision_tongue'] = np.zeros(cv_args['cv'].get_n_splits())\n\n    k = 0\n    max_acc = -np.inf\n    for train_index, val_index in cv_args['cv'].split(X_train, y_train):\n      X, X_val = X_train[train_index], X_train[val_index]\n      y, y_val = y_train[train_index], y_train[val_index]\n      print(val_index)\n\n      if model_args['autoencoder']:\n        y = [X, y]\n\n      batch_size, C, T = X.shape[:-1]\n\n      clear_session()\n      set_seed(seed)\n\n      model_cll, model_params = get_model(model_args['model_name'], model_args['nb_classes'])\n      model = model_cll(**model_params, Chans = C, Samples = T)\n      model.compile(loss = compile_args['loss'], \n                    optimizer = Adam(compile_args['init_lr']))\n      \n      history = model.fit(X, y,\n                batch_size = batch_size,\n                **fit_args)\n\n      if model_args['autoencoder']:\n        y_prob = model.predict(X_val)[-1]\n        y_pred = np.argmax(y_prob, axis = 1)\n      else:\n        y_prob = model.predict(X_val)\n        y_pred = np.argmax(y_prob, axis = 1)\n\n      cv_results['mean_acc'][k] = accuracy_score(y_val, y_pred)\n      cv_results['mean_kappa'][k] = cohen_kappa_score(y_val, y_pred)\n      if model_args['nb_classes'] == 2:\n        cv_results['mean_auc'][k] = roc_auc_score(y_val, y_prob[:, 1], average = 'macro')\n        cv_results['mean_f1_left'][k] = f1_score(y_val, y_pred, pos_label = 0, average = 'binary')\n        cv_results['mean_f1_right'][k] = f1_score(y_val, y_pred, pos_label = 1, average = 'binary')\n        cv_results['mean_recall_left'][k] = recall_score(y_val, y_pred, pos_label = 0, average = 'binary')\n        cv_results['mean_recall_right'][k] = recall_score(y_val, y_pred, pos_label = 1, average = 'binary')\n        cv_results['mean_precision_left'][k] = precision_score(y_val, y_pred, pos_label = 0, average = 'binary')\n        cv_results['mean_precision_right'][k] = precision_score(y_val, y_pred, pos_label = 1, average = 'binary')\n      else:                                                                                  \n        cv_results['mean_auc'][k] = roc_auc_score(y_val, y_prob, average = 'macro', multi_class = 'ovo')\n        \n        cv_results['mean_f1_left'][k] = f1_score(y_val, y_pred, pos_label = 0, average = 'micro')\n        cv_results['mean_f1_right'][k] = f1_score(y_val, y_pred, pos_label = 1, average = 'micro')\n        cv_results['mean_f1_legs'][k] = f1_score(y_val, y_pred, pos_label = 2, average = 'micro')\n        cv_results['mean_f1_tongue'][k] = f1_score(y_val, y_pred, pos_label = 3, average = 'micro')\n        cv_results['mean_recall_left'][k] = recall_score(y_val, y_pred, pos_label = 0, average = 'micro')\n        cv_results['mean_recall_right'][k] = recall_score(y_val, y_pred, pos_label = 1, average = 'micro')\n        cv_results['mean_recall_legs'][k] = recall_score(y_val, y_pred, pos_label = 2, average = 'micro')\n        cv_results['mean_recall_tongue'][k] = recall_score(y_val, y_pred, pos_label = 3, average = 'micro')\n        cv_results['mean_precision_left'][k] = precision_score(y_val, y_pred, pos_label = 0, average = 'micro')\n        cv_results['mean_precision_right'][k] = precision_score(y_val, y_pred, pos_label = 1, average = 'micro')\n        cv_results['mean_precision_legs'][k] = precision_score(y_val, y_pred, pos_label = 2, average = 'micro')\n        cv_results['mean_precision_tongue'][k] = precision_score(y_val, y_pred, pos_label = 3, average = 'micro')\n                                                       \n                                                       \n      if cv_results['mean_acc'][k]  > max_acc:\n        max_acc = cv_results['mean_acc'][k]\n        model.save_weights('sbj' + str(load_args['sbj']) +'.h5')\n\n      k += 1\n                                                \n    cv_results['std_acc'] = round(cv_results['mean_acc'].std(), 3)\n    cv_results['mean_acc'] = round(cv_results['mean_acc'].mean(), 3)\n    cv_results['std_kappa'] = round(cv_results['mean_kappa'].std(), 3)\n    cv_results['mean_kappa'] = round(cv_results['mean_kappa'].mean(), 3)\n    cv_results['std_auc'] = round(cv_results['mean_auc'].std(), 3)\n    cv_results['mean_auc'] = round(cv_results['mean_auc'].mean(), 3)\n      \n    cv_results['mean_f1_left'] = round(cv_results['mean_f1_left'].mean(), 3)\n    cv_results['std_f1_left'] = round(cv_results['mean_f1_left'].std(), 3)\n    cv_results['mean_f1_right'] = round(cv_results['mean_f1_right'].mean(), 3)\n    cv_results['std_f1_right'] = round(cv_results['mean_f1_right'].std(), 3)\n    cv_results['mean_recall_left'] = round(cv_results['mean_recall_left'].mean(), 3)\n    cv_results['std_recall_left'] = round(cv_results['mean_recall_left'].std(), 3)\n    cv_results['mean_recall_right'] = round(cv_results['mean_recall_right'].mean(), 3)\n    cv_results['std_recall_right'] = round(cv_results['mean_recall_right'].std(), 3)\n    cv_results['mean_precision_left'] = round(cv_results['mean_precision_left'].mean(), 3)\n    cv_results['std_precision_left'] = round(cv_results['mean_precision_left'].std(), 3)\n    cv_results['mean_precision_right'] = round(cv_results['mean_precision_right'].mean(), 3)\n    cv_results['std_precision_right'] = round(cv_results['mean_precision_right'].std(), 3)\n\n    if model_args['nb_classes'] == 4:\n        cv_results['mean_f1_legs'] = round(cv_results['mean_f1_legs'].mean(), 3)\n        cv_results['std_f1_legs'] = round(cv_results['mean_f1_legs'].std(), 3)\n        cv_results['mean_f1_tongue'] = round(cv_results['mean_f1_tongue'].mean(), 3)\n        cv_results['std_f1_tongue'] = round(cv_results['mean_f1_tongue'].std(), 3)\n        cv_results['mean_recall_legs'] = round(cv_results['mean_recall_legs'].mean(), 3)\n        cv_results['std_recall_legs'] = round(cv_results['mean_recall_legs'].std(), 3)\n        cv_results['mean_recall_tongue'] = round(cv_results['mean_recall_tongue'].mean(), 3)\n        cv_results['std_recall_tongue'] = round(cv_results['mean_recall_tongue'].std(), 3)\n        cv_results['mean_precision_legs'] = round(cv_results['mean_precision_legs'].mean(), 3)\n        cv_results['std_precision_legs'] = round(cv_results['mean_precision_legs'].std(), 3)\n        cv_results['mean_precision_tongue'] = round(cv_results['mean_precision_tongue'].mean(), 3)\n        cv_results['std_precision_tongue'] = round(cv_results['mean_precision_tongue'].std(), 3)\n    \n    return cv_results","metadata":{"id":"yE1sbHYQVbBq","execution":{"iopub.status.busy":"2024-07-11T00:59:55.127046Z","iopub.execute_input":"2024-07-11T00:59:55.127465Z","iopub.status.idle":"2024-07-11T01:00:02.466144Z","shell.execute_reply.started":"2024-07-11T00:59:55.127424Z","shell.execute_reply":"2024-07-11T01:00:02.464939Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"# Config","metadata":{"id":"uBAeW6J5S68g"}},{"cell_type":"code","source":"# Marcos, use these two variables to run the state of the art. First, for BCICIV2a run all the models.\n# Remeber that this network DMTL_BCI is an autoencoder. Set the nb_classses parameter depending of the database.\n# set autoencoder based on the model\n# We need to run all these tests again. Do not forget to add the recall, preci, and f1 for each class (bci 4, giga 2)\ndb_name = 'GIGA_MI_ME'\nmodel_args = dict(model_name = 'EEGNet',\n                  nb_classes = 2,\n                  autoencoder = False)","metadata":{"id":"2I3IQnNSS9-a","execution":{"iopub.status.busy":"2024-07-11T01:00:02.467744Z","iopub.execute_input":"2024-07-11T01:00:02.468419Z","iopub.status.idle":"2024-07-11T01:00:02.474662Z","shell.execute_reply.started":"2024-07-11T01:00:02.468383Z","shell.execute_reply":"2024-07-11T01:00:02.473389Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.callbacks import ReduceLROnPlateau, TerminateOnNaN\nimport numpy as np\nfrom tensorflow.keras.losses import SparseCategoricalCrossentropy, MeanSquaredError\nfrom sklearn.model_selection import StratifiedShuffleSplit\n\nif db_name == 'BCICIV2a':\n  db = Dataset_2a('/kaggle/input/dataset-2a')\n  fs = db.metadata['sampling_rate']\n  load_args = dict(db = db,\n                 fs = fs,\n                 f_bank = np.asarray([[4., 40.]]),\n                 vwt = np.asarray([[2.5, 6]]),\n                 new_fs = 128.)\n  subjects = np.arange(db.metadata['subjects']) + 1\n  \nelif db_name == 'GIGA_MI_ME':\n  db = GIGA_MI_ME('/kaggle/input/giga-science-gcpds/GIGA_MI_ME')\n  fs = db.metadata['sampling_rate']\n  eeg_ch_names = ['Fp1','Fpz','Fp2',\n                'AF7','AF3','AFz','AF4','AF8',\n                'F7','F5','F3','F1','Fz','F2','F4','F6','F8',\n                'FT7','FC5','FC3','FC1','FCz','FC2','FC4','FC6','FT8',\n                'T7','C5','C3','C1','Cz','C2','C4','C6','T8',\n                'TP7','CP5','CP3','CP1','CPz','CP2','CP4','CP6','TP8',\n                'P9','P7','P5','P3','P1','Pz','P2','P4','P6','P8','P10',\n                'PO7','PO3','POz','PO4','PO8',\n                'O1','Oz','O2',\n                'Iz']\n\n  load_args = dict(db = db,\n                  eeg_ch_names = eeg_ch_names,\n                  fs = fs,\n                  f_bank = np.asarray([[4., 40.]]),\n                  vwt = np.asarray([[2.5, 5]]),\n                  new_fs = 128.)\n  subjects = np.arange(db.metadata['subjects']) + 1\n  subjects = np.delete(subjects, [28,33])\n  \nelse:\n  raise ValueError('No valid database name')\n\nverbose = 0\nreduce_lr_on_plateau = ReduceLROnPlateau(monitor = 'loss', factor = 0.1, patience = 30, verbose = verbose, mode = 'min', min_delta = 0.01, min_lr = 0)\nterminate_on_nan = TerminateOnNaN()\ncallbacks = [reduce_lr_on_plateau, terminate_on_nan]\nseed = 23\n\ncv_args = dict(cv = StratifiedShuffleSplit(n_splits = 5, test_size = 0.2, random_state = seed))\n\ncompile_args = dict(loss = SparseCategoricalCrossentropy(), #['mse' , SparseCategoricalCrossentropy()]\n                    init_lr = 1e-2)\n                      \nfit_args = dict(epochs = 500,\n                verbose = verbose,\n                callbacks = callbacks)","metadata":{"id":"tqMhUFoBIc3B","outputId":"1405fd59-1374-4d5d-8e3a-5e7a45c79bba","execution":{"iopub.status.busy":"2024-07-11T01:00:02.478069Z","iopub.execute_input":"2024-07-11T01:00:02.478531Z","iopub.status.idle":"2024-07-11T01:00:02.503461Z","shell.execute_reply.started":"2024-07-11T01:00:02.478487Z","shell.execute_reply":"2024-07-11T01:00:02.502104Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"# Main","metadata":{"id":"ukhXifxzTaj9"}},{"cell_type":"code","source":"from pickle import dump\n\nfor sbj in subjects[:]:\n  print('sbj = ', sbj)\n  load_args['sbj'] = sbj\n  results = train(db_name, load_args, cv_args, model_args, compile_args, fit_args, seed)\n  with open('sbj' + str(load_args['sbj']) + '.txt', 'wb') as f:\n    dump(results, f)","metadata":{"id":"Ymqd_W21y3NK","outputId":"5ca97a2f-f57c-46ee-8f53-f00181ccea90","scrolled":true,"execution":{"iopub.status.busy":"2024-07-11T01:00:02.505214Z","iopub.execute_input":"2024-07-11T01:00:02.506213Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"sbj =  1\nResampling from 512.000000 to 128.000000 Hz.\n[ 25 107  31 188  83  86 111  75 191 170  76  12 100 154  73   6  66  54\n 104 162  91  51 132  39 105  40 134 141  45 116 185 178 127 150 194  69\n 133  90  64  49]\n[175 156   7 191  76 117  54  16   2  80  41 118  78  90 100 160 149 161\n 171  18  82 182 101  61  91 167 144 133 196  67  22  57 137 136  98 111\n  89  13 178  97]\n","output_type":"stream"}]},{"cell_type":"code","source":"!zip Models.zip ./*.h5\n!zip Results.zip ./*.txt","metadata":{"id":"V7-P0xjwzXVX","outputId":"270dceef-351d-48d1-f71e-2c3367c7fdac","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}