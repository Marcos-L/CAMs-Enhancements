{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":5175158,"sourceType":"datasetVersion","datasetId":3008205},{"sourceId":9678032,"sourceType":"datasetVersion","datasetId":5915127},{"sourceId":202552897,"sourceType":"kernelVersion"}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%%capture\n!pip install -U git+https://github.com/UN-GCPDS/python-gcpds.databases\n!pip install -U git+https://github.com/UN-GCPDS/python-gcpds.visualizations.git >/dev/null","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nfrom gcpds.visualizations.topoplots import topoplot\nimport matplotlib.pyplot as plt\nfrom sklearn.base import BaseEstimator, TransformerMixin\nfrom sklearn.model_selection import StratifiedShuffleSplit\nfrom scipy.signal import freqz, filtfilt, resample\nfrom scipy.signal import butter as bw\n\nfrom gcpds.databases import GIGA_MI_ME\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"channels = ['Fp1','Fpz','Fp2',\n            'AF7','AF3','AFz','AF4','AF8',\n            'F7','F5','F3','F1','Fz','F2','F4','F6','F8',\n            'FT7','FC5','FC3','FC1','FCz','FC2','FC4','FC6','FT8',\n            'T7','C5','C3','C1','Cz','C2','C4','C6','T8',\n            'TP7','CP5','CP3','CP1','CPz','CP2','CP4','CP6','TP8',\n            'P9','P7','P5','P3','P1','Pz','P2','P4','P6','P8','P10',\n            'PO7','PO3','POz','PO4','PO8',\n            'O1','Oz','O2',\n            'Iz']\n\nareas = {\n    'Frontal': ['Fpz', 'AFz', 'Fz', 'FCz'],\n    'Frontal Right': ['Fp2','AF4','AF8','F2','F4','F6','F8',],\n    'Central Right': ['FC2','FC4','FC6','FT8','C2','C4','C6','T8','CP2','CP4','CP6','TP8',],\n    'Posterior Right': ['P2','P4','P6','P8','P10','PO4','PO8','O2',],\n    #'Central': ['Cz'],\n    'Posterior': ['CPz','Pz', 'Cz','POz','Oz','Iz',],\n    'Posterior Left': ['P1','P3','P5','P7','P9','PO3','PO7','O1',],\n    'Central Left': ['FC1','FC3','FC5','FT7','C1','C3','C5','T7','CP1','CP3','CP5','TP7',],\n    'Frontal Left': ['Fp1','AF3','AF7','F1','F3','F5','F7',],\n}\n\narcs = [\n    #'hemispheres',\n    'areas',\n    'channels',\n]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def butterworth_digital_filter(X, N, Wn, btype, fs, axis=-1, padtype=None, padlen=0, method='pad', irlen=None):\n  \"\"\"\n  Apply digital butterworth filter\n  INPUT\n  ------\n  1. X: (D array)\n    array with signals.\n  2. N: (int+)\n    The order of the filter.\n  3. Wn: (float+ or 1D array)\n    The critical frequency or frequencies. For lowpass and highpass filters, Wn is a scalar; for bandpass and bandstop filters, Wn is a length-2 vector.\n    For a Butterworth filter, this is the point at which the gain drops to 1/sqrt(2) that of the passband (the “-3 dB point”).\n    If fs is not specified, Wn units are normalized from 0 to 1, where 1 is the Nyquist frequency (Wn is thus in half cycles / sample and defined as 2*critical frequencies / fs). If fs is specified, Wn is in the same units as fs.\n  4. btype: (str) {‘lowpass’, ‘highpass’, ‘bandpass’, ‘bandstop’}\n    The type of filter\n  5. fs: (float+)\n    The sampling frequency of the digital system.\n  6. axis: (int), Default=1.\n    The axis of x to which the filter is applied.\n  7. padtype: (str) or None, {'odd', 'even', 'constant'}\n    This determines the type of extension to use for the padded signal to which the filter is applied. If padtype is None, no padding is used. The default is ‘odd’.\n  8. padlen: (int+) or None, Default=0\n    The number of elements by which to extend x at both ends of axis before applying the filter. This value must be less than x.shape[axis] - 1. padlen=0 implies no padding.\n  9. method: (str), {'pad', 'gust'}\n    Determines the method for handling the edges of the signal, either “pad” or “gust”. When method is “pad”, the signal is padded; the type of padding is determined by padtype\n    and padlen, and irlen is ignored. When method is “gust”, Gustafsson’s method is used, and padtype and padlen are ignored.\n  10. irlen: (int) or None, Default=nONE\n    When method is “gust”, irlen specifies the length of the impulse response of the filter. If irlen is None, no part of the impulse response is ignored.\n    For a long signal, specifying irlen can significantly improve the performance of the filter.\n  OUTPUT\n  ------\n  X_fil: (D array)\n    array with filtered signals.\n  \"\"\"\n  b, a = bw(N, Wn, btype, analog=False, output='ba', fs=fs)\n  return filtfilt(b, a, X, axis=axis, padtype=padtype, padlen=padlen, method=method, irlen=irlen)\n\nclass TimeFrequencyRpr(BaseEstimator, TransformerMixin):\n  \"\"\"\n  Time frequency representation of EEG signals.\n\n  Parameters\n  ----------\n    1. sfreq:  (float) Sampling frequency in Hz.\n    2. f_bank: (2D array) Filter banks Frequencies. Default=None\n    3. vwt:    (2D array) Interest time windows. Default=None\n  Methods\n  -------\n    1. fit(X, y=None)\n    2. transform(X, y=None)\n  \"\"\"\n  def __init__(self, sfreq, f_bank=None, vwt=None):\n    self.sfreq = sfreq\n    self.f_bank = f_bank\n    self.vwt = vwt\n# ------------------------------------------------------------------------------\n\n  def _validation_param(self):\n    \"\"\"\n    Validate Time-Frequency characterization parameters.\n    INPUT\n    -----\n      1. self\n    ------\n      2. None\n    \"\"\"\n    if self.sfreq <= 0:\n      raise ValueError('Non negative sampling frequency is accepted')\n\n\n    if self.f_bank is None:\n      self.flag_f_bank = False\n    elif self.f_bank.ndim != 2:\n      raise ValueError('Band frequencies have to be a 2D array')\n    else:\n      self.flag_f_bank = True\n\n    if self.vwt is None:\n      self.flag_vwt = False\n    elif self.vwt.ndim != 2:\n      raise ValueError('Time windows have to be a 2D array')\n    else:\n      self.flag_vwt = True\n\n# ------------------------------------------------------------------------------\n  def _filter_bank(self, X):\n    \"\"\"\n    Filter bank Characterization.\n    INPUT\n    -----\n      1. X: (3D array) set of EEG signals, shape (trials, channels, time_samples)\n    OUTPUT\n    ------\n      1. X_f: (4D array) set of filtered EEG signals, shape (trials, channels, time_samples, frequency_bands)\n    \"\"\"\n    X_f = np.zeros((X.shape[0], X.shape[1], X.shape[2], self.f_bank.shape[0])) #epochs, Ch, Time, bands\n    for f in np.arange(self.f_bank.shape[0]):\n      X_f[:,:,:,f] = butterworth_digital_filter(X, N=5, Wn=self.f_bank[f], btype='bandpass', fs=self.sfreq)\n    return X_f\n\n# ------------------------------------------------------------------------------\n  def _sliding_windows(self, X):\n    \"\"\"\n    Sliding Windows Characterization.\n    INPUT\n    -----\n      1. X: (3D array) set of EEG signals, shape (trials, channels, time_samples)\n    OUTPUT\n    ------\n      1. X_w: (4D array) shape (trials, channels, window_time_samples, number_of_windows)\n    \"\"\"\n    window_lenght = int(self.sfreq*self.vwt[0,1] - self.sfreq*self.vwt[0,0])\n    X_w = np.zeros((X.shape[0], X.shape[1], window_lenght, self.vwt.shape[0]))\n    for w in np.arange(self.vwt.shape[0]):\n        X_w[:,:,:,w] = X[:,:,int(self.sfreq*self.vwt[w,0]):int(self.sfreq*self.vwt[w,1])]\n    return X_w\n\n# ------------------------------------------------------------------------------\n  def fit(self, X, y=None):\n    \"\"\"\n    fit.\n    INPUT\n    -----\n      1. X: (3D array) set of EEG signals, shape (trials, channels, time_samples)\n      2. y: (1D array) target labels. Default=None\n    OUTPUT\n    ------\n      1. None\n    \"\"\"\n    pass\n\n# ------------------------------------------------------------------------------\n  def transform(self, X, y=None):\n    \"\"\"\n    Time frequency representation of EEG signals.\n    INPUT\n    -----\n      1. X: (3D array) set of EEG signals, shape (trials, channels, times)\n    OUTPUT\n    ------\n      1. X_wf: (5D array) Time-frequency representation of EEG signals, shape (trials, channels, window_time_samples, number_of_windows, frequency_bands)\n    \"\"\"\n    self._validation_param()     #Validate sfreq, f_freq, vwt\n\n    #Avoid edge effects of digital filter, 1st:fbk, 2th:vwt\n    if self.flag_f_bank:\n        X_f = self._filter_bank(X)\n    else:\n        X_f = X[:,:,:,np.newaxis]\n\n    if self.flag_vwt:\n      X_wf = []\n      for f in range(X_f.shape[3]):\n        X_wf.append(self._sliding_windows(X_f[:,:,:,f]))\n      X_wf = np.stack(X_wf, axis=-1)\n    else:\n      X_wf = X_f[:,:,:,np.newaxis,:]\n\n    return X_wf\n\ndef kappa(y_true, y_pred):\n    return cohen_kappa_score(np.argmax(y_true, axis = 1),np.argmax(y_pred, axis = 1))\n\n# def minmax_norm(x):\n#     x = x - np.min(x)\n#     x = x/np.max(x)\n#     return x","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_GIGA(db,\n              sbj,\n              eeg_ch_names,\n              fs,\n              f_bank,\n              vwt,\n              new_fs,\n              run=None):\n\n    index_eeg_chs = db.format_channels_selectors(channels = eeg_ch_names) - 1\n\n    tf_repr = TimeFrequencyRpr(sfreq = fs, f_bank = f_bank, vwt = vwt)\n\n    db.load_subject(sbj)\n    if run == None:\n        X, y = db.get_data(classes = ['left hand mi', 'right hand mi']) #Load MI classes, all channels {EEG}, reject bad trials, uV\n    else:\n        X, y = db.get_run(run, classes = ['left hand mi', 'right hand mi']) #Load MI classes, all channels {EEG}, reject bad trials, uV\n    X = X[:, index_eeg_chs, :] #spatial rearrangement\n    X = np.squeeze(tf_repr.transform(X))\n    #Resampling\n    if new_fs == fs:\n        pass#print('No resampling, since new sampling rate same.')\n    else:\n        print(\"Resampling from {:f} to {:f} Hz.\".format(fs, new_fs))\n        X = resample(X, int((X.shape[-1]/fs)*new_fs), axis = -1)\n\n    return X, y","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.neighbors import KernelDensity\n\ndef shannon_entropy_kde(vector, bandwidth=1.0):\n    # Reshape the vector for KDE (it expects a 2D array)\n    vector = np.array(vector).reshape(-1, 1)\n    \n    # Perform kernel density estimation\n    kde = KernelDensity(bandwidth=bandwidth)\n    kde.fit(vector)\n    \n    # Generate a range of values to estimate the density over\n    min_val, max_val = vector.min(), vector.max()\n    grid = np.linspace(min_val, max_val, 1000).reshape(-1, 1)\n    \n    # Estimate the log density for each value in the grid\n    log_density = kde.score_samples(grid)\n    \n    # Convert log density to actual probability density\n    density = np.exp(log_density)\n    \n    # Normalize the density so that it sums to 1\n    density /= np.sum(density)\n    \n    # Calculate Shannon entropy\n    entropy = -np.sum(density * np.log2(density + np.finfo(float).eps))  # Add epsilon to avoid log(0)\n\n    return entropy\n\ndef entropy_of_matrix_columns_kde(matrix, bandwidth=1.0):\n    num_columns = matrix.shape[1]\n    entropies = []\n    \n    for col in range(num_columns):\n        column = matrix[:, col]\n        entropy = shannon_entropy_kde(column, bandwidth=bandwidth)\n        entropies.append(entropy)\n    \n    return entropies\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"db = GIGA_MI_ME('/kaggle/input/giga-science-gcpds/GIGA_MI_ME')\nload_args = dict(db = db,\n                 eeg_ch_names = channels,\n                 fs = db.metadata['sampling_rate'],\n                 f_bank = np.asarray([[4., 40.]]),\n                 vwt = np.asarray([[2.5, 5]]),\n                 new_fs = 128.)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#subjects groups\ng1 = [0, 2, 3, 4, 5, 9, 12, 13, 22, 25, 27, 32, 34, 38, 40, 41, 43, 44, 45, 46, 47]\ng2 = [7, 8, 11, 14, 17, 19, 20, 21, 23, 24, 29, 33, 36, 39, 42, 48, 49]\ng3 = [1, 6, 10, 15, 16, 18, 26, 28, 30, 31, 35, 37]\ng_ = [g1,g2,g3]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nplot_ = True\nfs = 128\nnum_classes = 2\nnum_channels = 64\nnum_topo = 4\n\nsubjects = np.arange(52)+1\nsubjects = np.delete(subjects,[28,33]) # delete 29 and 34\n\nnum_sbj = len(subjects)\n\nS_mean_topomaps_per_ch_ = np.zeros((num_sbj,num_channels,num_topo,num_classes))\nS_mean_topomaps_false_true = np.zeros((num_sbj,num_channels,num_classes+1,num_classes))\nS_entropy = np.zeros((num_sbj,num_topo,num_classes))\n\n\nmodel_ = ['EEGNet', 'KREEGNet', 'KCS-FCNet', 'DeepConv', 'ShallowConv', 'TCFusion']\n\n\n\nfor mod_ in model_:\n    try:\n        os.mkdir(mod_)\n    except:\n        pass\n\n    path_false = '/kaggle/input/true-false-cams/cams/False_Cams_'+mod_+'.npy'\n    path_true = '/kaggle/input/true-false-cams/cams/True_Cams_'+mod_+'.npy'\n    false_cams = np.load(path_false)\n    true_cams = np.load(path_true)\n\n    for ii, sbj in enumerate(subjects):\n        #sbj = 43\n        print(f'sbj {ii+1}/{num_sbj}: Num#: {sbj}')\n        sbj_index = np.where(subjects==sbj)[0]\n        X_train, y_train = load_GIGA(sbj=sbj, **load_args)\n        X_train = np.expand_dims(X_train, -1)\n\n        SSS = StratifiedShuffleSplit(n_splits = 5, test_size=0.2, random_state = 23)\n        partitions = list(SSS.split(X_train, y_train))\n\n        test_trials = partitions[4][1]\n        labels = y_train[test_trials]\n        left_trials = np.where(y_train[test_trials]==0)[0]\n        right_trials = np.where(y_train[test_trials]==1)[0]\n        left_trials, right_trials\n\n\n        num_trials = np.max((left_trials.shape[0], right_trials.shape[0]))\n        vfreq = np.fft.rfftfreq(X_train.shape[2],1/fs)\n        num_fft = len(vfreq)\n        num_time = 320\n        topomaps_per_trial = np.zeros((num_trials, num_channels, num_fft, num_classes))\n        topomaps_per_ch_trial = np.zeros((num_trials, num_channels, num_topo,num_classes))\n        topomaps_per_false_true = np.zeros((num_trials, num_channels,num_classes+1,num_classes))\n\n        all_ = (vfreq >=4) & (vfreq<=40) # 4 - 40\n        theta_ = (vfreq >=4) & (vfreq<8)\n        alpha_ = (vfreq >=8) & (vfreq<13)\n        beta_ = (vfreq >=13) & (vfreq<=30)\n\n        for i, side in enumerate([left_trials, right_trials]):\n            for j, trial in enumerate(side):\n                true_cam_ = true_cams[sbj_index[0], test_trials[trial]]\n                false_cam_ = false_cams[sbj_index[0], test_trials[trial]]\n                \n                #filtro y reconstruccion\n                true_cam_ = np.fft.rfft(true_cam_,axis=1)\n                true_cam_[:,~all_] = 0\n                true_cam_ = abs(np.fft.irfft(true_cam_,axis=1))\n                false_cam_ = np.fft.rfft(false_cam_,axis=1)\n                false_cam_[:,~all_] = 0\n                false_cam_ = abs(np.fft.irfft(false_cam_,axis=1))\n                \n                max_val = np.max(np.concatenate((true_cam_, false_cam_), axis=0))\n\n                true_cam_ /= max_val\n                false_cam_ /= max_val\n                diff_cam = true_cam_-false_cam_\n                diff_cam /= np.max(abs(diff_cam))\n                #diff_cam = 2*diff_cam + 1\n                \n                \n           \n                topomaps_per_false_true[j,:,0,i] = false_cam_.mean(axis=1)\n                topomaps_per_false_true[j,:,1,i] = true_cam_.mean(axis=1)\n                topomaps_per_false_true[j,:,2,i] = diff_cam.mean(axis=1)\n                topomaps_per_trial[j, :, :, i] = abs(np.fft.rfft(diff_cam,axis=1))\n                topomaps_per_trial[j, :, :, i] /= np.max(topomaps_per_trial[j, :, :, i])\n                topomaps_per_ch_trial[j,:,0,i] = topomaps_per_trial[j, :, all_, i].mean(axis=0) \n                topomaps_per_ch_trial[j,:,1,i] = topomaps_per_trial[j, :, theta_, i].mean(axis=0) \n                topomaps_per_ch_trial[j,:,2,i] = topomaps_per_trial[j, :, alpha_, i].mean(axis=0) \n                topomaps_per_ch_trial[j,:,3,i] = topomaps_per_trial[j, :, beta_, i].mean(axis=0) \n                topomaps_per_ch_trial[j,:,:,i] /= np.max(topomaps_per_ch_trial[j,:,:,i])\n\n        #trials mean\n        mean_topo_false_true = topomaps_per_false_true.mean(axis=0)\n        #mean_topo_false_true -= np.min(mean_topo_false_true)\n        mean_topo_false_true /= np.max(mean_topo_false_true)\n        \n        mean_topomaps_per_ch_ = topomaps_per_ch_trial.mean(axis=0)\n        #mean_topomaps_per_ch_ -= np.min(mean_topomaps_per_ch_)\n        mean_topomaps_per_ch_ /= np.max(mean_topomaps_per_ch_)\n        \n        #mean_topomaps_per_ch_ = 2*mean_topomaps_per_ch_ +1\n        #mean_topo_false_true = 2*mean_topo_false_true +1\n        vmin_ = 0\n        vmax_ = 1\n\n\n        entropy_ = np.zeros((num_topo,num_classes))\n\n        for c in range(num_classes):\n            entropy_[:,c] = entropy_of_matrix_columns_kde(mean_topomaps_per_ch_[:,:,c],bandwidth=0.1)       \n\n        S_mean_topomaps_false_true[ii] = mean_topo_false_true\n        S_mean_topomaps_per_ch_[ii] = mean_topomaps_per_ch_\n        S_entropy[ii] = entropy_\n\n\n        if plot_:\n            fig, ax = plt.subplot_mosaic([['false_l','true_l',],#'diff_l','og_l','theta_l', 'alpha_l', 'beta_l'],\n                                          ['false_r','true_r',]],#'diff_r','og_r','theta_r', 'alpha_r', 'beta_r']],\n                                         figsize=(4,8),gridspec_kw={'wspace': 0.02,'hspace': -0.55})\n            img,_=topoplot(mean_topo_false_true[:,0,0], channels, cmap='viridis',ax=ax['false_l'], vlim=(vmin_, vmax_), show=False)\n            topoplot(mean_topo_false_true[:,1,0], channels, cmap='viridis',ax=ax['true_l'], vlim=(vmin_, vmax_), show=False)\n            #topoplot(mean_topo_false_true[:,2,0], channels, cmap='viridis',ax=ax['diff_l'], vlim=(vmin_, vmax_), show=False)\n\n            #topoplot(mean_topomaps_per_ch_[:,0,0], channels, cmap='viridis',ax=ax['og_l'], vlim=(vmin_, vmax_), show=False)\n            #topoplot(mean_topomaps_per_ch_[:,1,0], channels, cmap='viridis',ax=ax['theta_l'],vlim=(vmin_, vmax_), show=False)\n            #topoplot(mean_topomaps_per_ch_[:,2,0], channels, cmap='viridis',ax=ax['alpha_l'],vlim=(vmin_, vmax_), show=False)\n            #topoplot(mean_topomaps_per_ch_[:,3,0], channels, cmap='viridis',ax=ax['beta_l'],vlim=(vmin_, vmax_), show=False)\n\n            ax['false_l'].set_title(f'False', size=20)\n            ax['true_l'].set_title(f'True', size=20)\n            #ax['diff_l'].set_title(f'Diff', size=20)\n            #ax['og_l'].set_title(f'[4-40]', size=20)\n            #ax['theta_l'].set_title(f'[4-8]', size=20)\n            #ax['alpha_l'].set_title(f'[8-13]', size=20)\n            #ax['beta_l'].set_title(f'[13-30]', size=20)\n\n            topoplot(mean_topo_false_true[:,0,1], channels, cmap='viridis',ax=ax['false_r'], vlim=(vmin_, vmax_), show=False)\n            topoplot(mean_topo_false_true[:,1,1], channels, cmap='viridis',ax=ax['true_r'], vlim=(vmin_, vmax_), show=False)\n            #topoplot(mean_topo_false_true[:,2,1], channels, cmap='viridis',ax=ax['diff_r'], vlim=(vmin_, vmax_), show=False)\n\n            #topoplot(mean_topomaps_per_ch_[:,0,1], channels, cmap='viridis',ax=ax['og_r'], vlim=(vmin_, vmax_), show=False)\n            #topoplot(mean_topomaps_per_ch_[:,1,1], channels, cmap='viridis',ax=ax['theta_r'],vlim=(vmin_, vmax_), show=False)\n            #topoplot(mean_topomaps_per_ch_[:,2,1], channels, cmap='viridis',ax=ax['alpha_r'],vlim=(vmin_, vmax_), show=False)\n            #topoplot(mean_topomaps_per_ch_[:,3,1], channels, cmap='viridis',ax=ax['beta_r'],vlim=(vmin_, vmax_), show=False)\n\n            #Agrego colorbar asi para que la ultima cabeza no se ponga más pequeña\n            cbar_ax = fig.add_axes([0.92, 0.3, 0.015, 0.4])\n            fig.colorbar(img, cax=cbar_ax)\n            cbar_ax.tick_params(labelsize=20)\n            plt.savefig(f'{mod_}/Sbj{sbj}_{mod_}.pdf', bbox_inches='tight')\n            #plt.show()\n    for g in range(3):\n        #mean_ = np.median(S_mean_topomaps_per_ch_[g_[g]],axis=0)\n        mean_freq = np.mean(S_mean_topomaps_per_ch_[g_[g]],axis=0)\n        mean_ft = np.mean(S_mean_topomaps_false_true[g_[g]],axis=0)\n        mean_freq /= np.max(mean_freq)\n        mean_ft /= np.max(mean_ft)\n\n        fig, ax = plt.subplot_mosaic([['false_l','true_l',],#'diff_l','og_l','theta_l', 'alpha_l', 'beta_l'],\n                                      ['false_r','true_r',]],#'diff_r','og_r','theta_r', 'alpha_r', 'beta_r']],\n                                     figsize=(4,8),gridspec_kw={'wspace': 0.02,'hspace': -0.55})\n        img,_=topoplot(mean_ft[:,0,0], channels, cmap='viridis',ax=ax['false_l'], vlim=(vmin_, vmax_), show=False)\n        topoplot(mean_ft[:,1,0], channels, cmap='viridis',ax=ax['true_l'], vlim=(vmin_, vmax_), show=False)\n        #topoplot(mean_ft[:,2,0], channels, cmap='viridis',ax=ax['diff_l'], vlim=(vmin_, vmax_), show=False)\n\n        #topoplot(mean_freq[:,0,0], channels, cmap='viridis',ax=ax['og_l'], vlim=(vmin_, vmax_), show=False)\n        #topoplot(mean_freq[:,1,0], channels, cmap='viridis',ax=ax['theta_l'],vlim=(vmin_, vmax_), show=False)\n        #topoplot(mean_freq[:,2,0], channels, cmap='viridis',ax=ax['alpha_l'],vlim=(vmin_, vmax_), show=False)\n        #topoplot(mean_freq[:,3,0], channels, cmap='viridis',ax=ax['beta_l'],vlim=(vmin_, vmax_), show=False)\n\n        ax['false_l'].set_title(f'False'+'--G'+str(g+1), size=20)\n        ax['true_l'].set_title(f'True', size=20)\n        #ax['diff_l'].set_title(f'Diff', size=20)\n        #ax['og_l'].set_title(f'[4-40]', size=20)\n        #ax['theta_l'].set_title(f'[4-8]', size=20)\n        #ax['alpha_l'].set_title(f'[8-13]', size=20)\n        #ax['beta_l'].set_title(f'[13-30]', size=20)\n\n        topoplot(mean_ft[:,0,1], channels, cmap='viridis',ax=ax['false_r'], vlim=(vmin_, vmax_), show=False)\n        topoplot(mean_ft[:,1,1], channels, cmap='viridis',ax=ax['true_r'], vlim=(vmin_, vmax_), show=False)\n        #topoplot(mean_ft[:,2,1], channels, cmap='viridis',ax=ax['diff_r'], vlim=(vmin_, vmax_), show=False)\n\n        #topoplot(mean_freq[:,0,1], channels, cmap='viridis',ax=ax['og_r'], vlim=(vmin_, vmax_), show=False)\n        #topoplot(mean_freq[:,1,1], channels, cmap='viridis',ax=ax['theta_r'],vlim=(vmin_, vmax_), show=False)\n        #topoplot(mean_freq[:,2,1], channels, cmap='viridis',ax=ax['alpha_r'],vlim=(vmin_, vmax_), show=False)\n        #topoplot(mean_freq[:,3,1], channels, cmap='viridis',ax=ax['beta_r'],vlim=(vmin_, vmax_), show=False)\n\n        #Agrego colorbar asi para que la ultima cabeza no se ponga más pequeña\n        cbar_ax = fig.add_axes([0.92, 0.3, 0.015, 0.4])\n        fig.colorbar(img, cax=cbar_ax)\n        cbar_ax.tick_params(labelsize=20)\n\n        plt.savefig('Topo_'+mod_+'_G'+str(g+1)+\".pdf\", format=\"pdf\", bbox_inches=\"tight\")\n        #plt.show()  ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#true_cam_ = true_cams[sbj_index[0], test_trials[trial]]\n#true_cam_f = np.fft.rfft(true_cam_,axis=1)\n#true_cam_f[:,~all_] = 0\n#true_cam_f = abs(np.fft.irfft(true_cam_f,axis=1))\n#plt.plot(true_cam_f.T)\n#plt.show()\n\n#plt.plot(true_cam_.T)\n#plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#S_mean_topomaps_per_ch_ = np.zeros((num_sbj,num_channels,num_topo,num_classes))\n#S_entropy = np.zeros((num_sbj,num_topo,num_classes))\n#file_ = 'cams_diff_norm'\n#np.savez(file_,S_mean_topomap=S_mean_topomaps_per_ch_,entropy_cam=S_entropy,sbjs = subjects)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}