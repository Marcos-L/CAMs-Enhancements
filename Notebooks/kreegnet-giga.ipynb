{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":2702226,"sourceType":"datasetVersion","datasetId":1269900},{"sourceId":5175158,"sourceType":"datasetVersion","datasetId":3008205}],"dockerImageVersionId":30236,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%%capture\n!pip install -U git+https://github.com/UN-GCPDS/python-gcpds.databases #Package for database reading.\n!pip install mne #The MNE Package is installed\nFILEID = \"1lo0MjWLvsyne2CgTA6VZ2HGY9SKxiwZ7\"\n!wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id='$FILEID -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=\"$FILEID -O MI_EEG_ClassMeth.zip && rm -rf /tmp/cookies.txt\n!unzip MI_EEG_ClassMeth.zip #Package with useful functions for motor imagery classification based in EEG.\n!dir","metadata":{"id":"K0oS6IH7VTZX","execution":{"iopub.status.busy":"2024-07-23T14:02:22.387003Z","iopub.execute_input":"2024-07-23T14:02:22.387429Z","iopub.status.idle":"2024-07-23T14:02:58.486495Z","shell.execute_reply.started":"2024-07-23T14:02:22.387336Z","shell.execute_reply":"2024-07-23T14:02:58.485145Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!apt-get install --allow-change-held-packages libcudnn8=8.1.0.77-1+cuda11.2 -y\n!pip install tensorflow==2.8.2","metadata":{"execution":{"iopub.status.busy":"2024-07-23T14:02:58.488816Z","iopub.execute_input":"2024-07-23T14:02:58.489130Z","iopub.status.idle":"2024-07-23T14:04:53.895024Z","shell.execute_reply.started":"2024-07-23T14:02:58.489098Z","shell.execute_reply":"2024-07-23T14:04:53.893970Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from gcpds.databases import GIGA_MI_ME\nfrom typing import Sequence, Tuple\nfrom MI_EEG_ClassMeth.FeatExtraction import TimeFrequencyRpr\nimport numpy as np\nfrom scipy.signal import resample\n\ndef load_GIGA(db: GIGA_MI_ME,\n              sbj: int,\n              eeg_ch_names: Sequence[str],\n              fs: float, \n              f_bank: np.ndarray, \n              vwt: np.ndarray, \n              new_fs: float) -> Tuple[np.ndarray, np.ndarray]:\n\n  index_eeg_chs = db.format_channels_selectors(channels = eeg_ch_names) - 1\n\n  tf_repr = TimeFrequencyRpr(sfreq = fs, f_bank = f_bank, vwt = vwt)\n\n  db.load_subject(sbj)\n  X, y = db.get_data(classes = ['left hand mi', 'right hand mi']) #Load MI classes, all channels {EEG}, reject bad trials, uV\n  X = X[:, index_eeg_chs, :] #spatial rearrangement\n  X = np.squeeze(tf_repr.transform(X))\n  #Resampling\n  if new_fs == fs:\n    print('No resampling, since new sampling rate same.')\n  else:\n    print(\"Resampling from {:f} to {:f} Hz.\".format(fs, new_fs))\n    X = resample(X, int((X.shape[-1]/fs)*new_fs), axis = -1)\n    \n  return X, y\n\nfrom tensorflow.keras.layers import Layer\nimport tensorflow as tf\nimport tensorflow_probability as tfp\n\nclass GFC(Layer):\n  def __init__(self, **kwargs):\n    super().__init__(**kwargs)\n\n  def build(self, batch_input_shape):\n    self.gammad = self.add_weight(name = 'gammad',\n                            shape = (),\n                            initializer = 'zeros',\n                            trainable = True)\n    super().build(batch_input_shape)\n\n  def call(self, X): \n    X = tf.transpose(X, perm  = (0, 3, 1, 2)) #(N, F, C, T)\n    R = tf.reduce_sum(tf.math.multiply(X, X), axis = -1, keepdims = True) #(N, F, C, 1)\n    D  = R - 2*tf.matmul(X, X, transpose_b = (0, 1, 3, 2)) + tf.transpose(R, perm = (0, 1, 3, 2)) #(N, F, C, C)\n\n    ones = tf.ones_like(D[0,0,...]) #(C, C)\n    mask_a = tf.linalg.band_part(ones, 0, -1) #Upper triangular matrix of 0s and 1s (C, C)\n    mask_b = tf.linalg.band_part(ones, 0, 0)  #Diagonal matrix of 0s and 1s (C, C)\n    mask = tf.cast(mask_a - mask_b, dtype=tf.bool) #Make a bool mask (C, C)\n    triu = tf.expand_dims(tf.boolean_mask(D, mask, axis = 2), axis = -1) #(N, F, C*(C-1)/2, 1)\n    sigma = tfp.stats.percentile(tf.math.sqrt(triu), 50, axis = 2, keepdims = True) #(N, F, 1, 1)\n\n    A = tf.math.exp(-1/(2*tf.pow(10., self.gammad)*tf.math.square(sigma))*D) #(N, F, C, C)\n    A.set_shape(D.shape)\n    return A\n\n  def compute_output_shape(self, batch_input_shape):\n    N, C, T, F = batch_input_shape.as_list()\n    return tf.TensorShape([N, F, C, C])\n\n  def get_config(self):\n    base_config = super().get_config()\n    return {**base_config}\n\nfrom tensorflow.keras.layers import Input, Conv2D, BatchNormalization, DepthwiseConv2D, Activation, AveragePooling2D, Dropout, SpatialDropout2D, SeparableConv2D, Flatten, Dense\nfrom tensorflow.keras.constraints import max_norm\nfrom tensorflow.keras.models import Model\n\ndef get_model(number_of_classes: int,\n          number_of_channels: int,\n          number_of_time_samples: int, \n          dropout_rate: float,\n          kernLength: int,\n          F1: int, \n          D: int,\n          F2: int,\n          norm_rate: int,\n          dropout_type: str) -> Model:\n    \"\"\" Keras Implementation of EEGNet\n    http://iopscience.iop.org/article/10.1088/1741-2552/aace8c/meta\n    Note that this implements the newest version of EEGNet and NOT the earlier\n    version (version v1 and v2 on arxiv). We strongly recommend using this\n    architecture as it performs much better and has nicer properties than\n    our earlier version. For example:\n        \n        1. Depthwise Convolutions to learn spatial filters within a \n        temporal convolution. The use of the depth_multiplier option maps \n        exactly to the number of spatial filters learned within a temporal\n        filter. This matches the setup of algorithms like FBCSP which learn \n        spatial filters within each filter in a filter-bank. This also limits \n        the number of free parameters to fit when compared to a fully-connected\n        convolution. \n        \n        2. Separable Convolutions to learn how to optimally combine spatial\n        filters across temporal bands. Separable Convolutions are Depthwise\n        Convolutions followed by (1x1) Pointwise Convolutions. \n        \n    \n    While the original paper used Dropout, we found that SpatialDropout2D \n    sometimes produced slightly better results for classification of ERP \n    signals. However, SpatialDropout2D significantly reduced performance \n    on the Oscillatory dataset (SMR, BCI-IV Dataset 2A). We recommend using\n    the default Dropout in most cases.\n        \n    Assumes the input signal is sampled at 128Hz. If you want to use this model\n    for any other sampling rate you will need to modify the lengths of temporal\n    kernels and average pooling size in blocks 1 and 2 as needed (double the \n    kernel lengths for double the sampling rate, etc). Note that we haven't \n    tested the model performance with this rule so this may not work well. \n    \n    The model with default parameters gives the EEGNet-8,2 model as discussed\n    in the paper. This model should do pretty well in general, although it is\n\tadvised to do some model searching to get optimal performance on your\n\tparticular dataset.\n    We set F2 = F1 * D (number of input filters = number of output filters) for\n    the SeparableConv2D layer. We haven't extensively tested other values of this\n    parameter (say, F2 < F1 * D for compressed learning, and F2 > F1 * D for\n    overcomplete). We believe the main parameters to focus on are F1 and D. \n    Inputs:\n        \n      nb_classes      : int, number of classes to classify\n      number_of_channels, number_of_time_samples  : number of channels and time points in the EEG data\n      dropout_rate     : dropout fraction\n      kernLength      : length of temporal convolution in first layer. We found\n                        that setting this to be half the sampling rate worked\n                        well in practice. For the SMR dataset in particular\n                        since the data was high-passed at 4Hz we used a kernel\n                        length of 32.     \n      F1, F2          : number of temporal filters (F1) and number of pointwise\n                        filters (F2) to learn. Default: F1 = 8, F2 = F1 * D. \n      D               : number of spatial filters to learn within each temporal\n                        convolution. Default: D = 2\n      dropout_type     : Either SpatialDropout2D or Dropout, passed as a string.\n    \"\"\"\n    \n    if dropout_type == 'SpatialDropout2D':\n        dropout_type = SpatialDropout2D\n    elif dropout_type == 'Dropout':\n        dropout_type = Dropout\n    else:\n        raise ValueError('dropout_type must be one of SpatialDropout2D '\n                         'or Dropout, passed as a string.')\n    \n    input_   = Input(shape = (number_of_channels, number_of_time_samples, 1))\n\n    ##################################################################\n    #Temporal Convolution\n    block1       = Conv2D(F1, (1, kernLength), padding = 'same',\n                          name = 'Temporal_Conv2D',\n                          use_bias = False)(input_)\n    block1       = BatchNormalization()(block1)\n    adj_mat      = GFC(name = 'gfc')(block1)\n    \n    ##################################################################\n    #Spatial Convolution\n    block1       = DepthwiseConv2D((number_of_channels, 1),\n                                   name = 'Spatial_Depth_wise_Conv2D',\n                                   depth_multiplier = D,\n                                   use_bias = False, \n                                   depthwise_constraint = max_norm(1.))(block1)\n    block1       = BatchNormalization()(block1)\n    block1       = Activation('elu')(block1)\n    block1       = AveragePooling2D((1, 4))(block1)\n    block1       = dropout_type(dropout_rate)(block1)\n    \n    ##################################################################\n    #Separable Convolution\n    block2       = SeparableConv2D(F2, (1, 16), padding = 'same',\n                                   name = 'Separable_Conv2D',\n                                   use_bias = False)(block1)\n    block2       = BatchNormalization()(block2)\n    block2       = Activation('elu')(block2)\n    block2       = AveragePooling2D((1, 8))(block2)\n    block2       = dropout_type(dropout_rate)(block2)\n    \n    ##################################################################\n    # Classification block\n    flatten      = Flatten(name = 'flatten')(block2)\n    dense        = Dense(number_of_classes, name = 'output', \n                         kernel_constraint = max_norm(norm_rate))(flatten)\n    softmax      = Activation('softmax', name = 'out_activation')(dense)\n    \n    return Model(inputs=input_, outputs = [softmax, adj_mat])\n\nfrom typing import Callable\nimport tensorflow as tf\nimport keras.backend as K\n\ndef adjacency_matrix_regularization(y_true: tf.Tensor, y_pred: tf.Tensor) -> tf.Tensor:\n    global N\n    F = y_pred.shape[1]\n    C = y_pred.shape[-1]\n    scalar_kernely = tfp.math.psd_kernels.ExponentiatedQuadratic(amplitude = 1, length_scale = 1e-13)\n    y_true = tf.cast(y_true, dtype = tf.float32)\n    y_true = tf.expand_dims(y_true, axis = -1) #(N, 1)\n    Ky = scalar_kernely.matrix(y_true, y_true) #(N, N)\n    #N = Ky.shape[-1]\n    Ky = tf.expand_dims(Ky, axis = 0) #(1, N, N)\n    ones = tf.ones_like(y_pred[0, 0, ...])\n    mask_a = tf.linalg.band_part(ones, 0, -1) #Upper triangular matrix of 0s and 1s\n    mask_b = tf.linalg.band_part(ones, 0, 0)  #Diagonal matrix of 0s and 1s\n    mask = tf.cast(mask_a - mask_b, dtype = tf.bool) #Make a bool mask\n    A = tf.boolean_mask(y_pred, mask, axis = 2) #(N, F, C(C - 1)/2)\n    A.set_shape([N, F, int(C*(C - 1)*0.5)])\n    A = tf.linalg.normalize(A, ord = 'euclidean', axis = -1)[0] #Normalize connectivities vectors\n    A = tf.transpose(A, perm  = (1, 0, 2)) #(F, N, C(C - 1)/2)\n    Ka = tf.linalg.matmul(A, A, transpose_b = True) #(F, N, N)\n    h = tf.eye(N) - (1.0/N)*tf.ones([N,1])*tf.ones([1,N]) #matrix for centered kernel\n    trkl = tf.linalg.trace(tf.matmul(tf.matmul(Ka,h), tf.matmul(Ky,h)))\n    trkk = tf.linalg.trace(tf.matmul(tf.matmul(Ka,h),tf.matmul(Ka,h)))\n    trll = tf.linalg.trace(tf.matmul(tf.matmul(Ky,h),tf.matmul(Ky,h)))\n    loss = tf.math.reduce_sum(-trkl/tf.sqrt(trkk*trll))/F\n    return loss","metadata":{"id":"yE1sbHYQVbBq","execution":{"iopub.status.busy":"2024-07-23T14:12:23.324450Z","iopub.execute_input":"2024-07-23T14:12:23.324882Z","iopub.status.idle":"2024-07-23T14:12:23.373046Z","shell.execute_reply.started":"2024-07-23T14:12:23.324849Z","shell.execute_reply":"2024-07-23T14:12:23.371957Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.callbacks import ReduceLROnPlateau, TerminateOnNaN\nimport numpy as np\nfrom tensorflow.keras.losses import SparseCategoricalCrossentropy\nfrom tensorflow.keras.optimizers import Adam\nfrom sklearn.model_selection import StratifiedShuffleSplit\nfrom os import makedirs\n\ndb = GIGA_MI_ME('/kaggle/input/giga-science-gcpds/GIGA_MI_ME')\nfs = db.metadata['sampling_rate']\neeg_ch_names = ['Fp1','Fpz','Fp2',\n              'AF7','AF3','AFz','AF4','AF8',\n              'F7','F5','F3','F1','Fz','F2','F4','F6','F8',\n              'FT7','FC5','FC3','FC1','FCz','FC2','FC4','FC6','FT8',\n              'T7','C5','C3','C1','Cz','C2','C4','C6','T8',\n              'TP7','CP5','CP3','CP1','CPz','CP2','CP4','CP6','TP8',\n              'P9','P7','P5','P3','P1','Pz','P2','P4','P6','P8','P10',\n              'PO7','PO3','POz','PO4','PO8',\n              'O1','Oz','O2',\n              'Iz']\nverbose = 0\nreduce_lr_on_plateau = ReduceLROnPlateau(monitor = 'loss', factor = 0.1, patience = 30, verbose = verbose, mode = 'min', min_delta = 0.01, min_lr = 0)\nterminate_on_nan = TerminateOnNaN()\ncallbacks = [reduce_lr_on_plateau, terminate_on_nan]\nseed = 23\n\nload_args = dict(db = db,\n                 eeg_ch_names = eeg_ch_names,\n                 fs = fs,\n                 f_bank = np.asarray([[4., 40.]]),\n                 vwt = np.asarray([[2.5, 5]]),\n                 new_fs = 128.)\n\ncv_args = dict(hyparams = [0, 0.2, 0.4, 0.6, 0.8],\n               cv = StratifiedShuffleSplit(n_splits = 5, test_size = 0.2, random_state = seed))\n\nmodel_args = dict(number_of_classes = 2,\n                  dropout_rate = 0.5,\n                  kernLength = int(load_args['new_fs']/4),\n                  F1 = 8,\n                  D = 2,\n                  F2 = 16,\n                  norm_rate = 0.25,\n                  dropout_type = 'Dropout')\n\ncompile_args = dict(loss = [SparseCategoricalCrossentropy(), adjacency_matrix_regularization],\n                    init_lr = 1e-2)\n                        \nfit_args = dict(epochs = 500,\n                verbose = verbose,\n                callbacks = callbacks)","metadata":{"execution":{"iopub.status.busy":"2024-07-23T14:09:45.434702Z","iopub.execute_input":"2024-07-23T14:09:45.435541Z","iopub.status.idle":"2024-07-23T14:09:45.450219Z","shell.execute_reply.started":"2024-07-23T14:09:45.435505Z","shell.execute_reply":"2024-07-23T14:09:45.449273Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.random import set_seed\nfrom tensorflow.keras.backend import clear_session\nfrom sklearn.metrics import accuracy_score, cohen_kappa_score, roc_auc_score\n\ndef train(load_args, cv_args, model_args, compile_args, fit_args, seed):\n    global N\n    X_train, y_train = load_GIGA(**load_args)\n    X_train = X_train[..., np.newaxis]\n\n    cv_results = {'params': [], 'mean_acc':[], 'std_acc':[],\n                  'mean_kappa':[], 'std_kappa':[],\n                  'mean_auc':[], 'std_auc':[]}\n    # add measurements\n\n    for lambda_ in cv_args['hyparams']:\n      cv_results['params'].append(lambda_)\n      acc = np.zeros(cv_args['cv'].get_n_splits())\n      kappa = np.zeros(cv_args['cv'].get_n_splits())\n      auc = np.zeros(cv_args['cv'].get_n_splits())\n        # init vectors\n      k = 0\n      for train_index, val_index in cv_args['cv'].split(X_train, y_train):\n        X, X_val = X_train[train_index], X_train[val_index]\n        y, y_val = y_train[train_index], y_train[val_index]\n\n        batch_size, C, T = X.shape[:-1]\n        \n        N = batch_size\n\n        clear_session()\n        set_seed(seed)\n\n        model = get_model(**model_args, number_of_channels = C, number_of_time_samples = T)\n        model.compile(loss = compile_args['loss'], \n                      loss_weights = [1 - lambda_, lambda_],\n                      optimizer = Adam(compile_args['init_lr']))\n        \n        history = model.fit(X, [y, y],\n                  batch_size = batch_size,\n                  **fit_args)\n\n        y_prob = model.predict(X_val)[0]\n        y_pred = np.argmax(y_prob, axis = 1)\n\n        acc[k] = accuracy_score(y_val, y_pred)\n        kappa[k] = cohen_kappa_score(y_val, y_pred)\n        auc[k] = roc_auc_score(y_val, y_prob[:, 1], average = 'macro')\n        # f1, recall, preci (0, 1)\n\n        print('lambda = ', lambda_, ', Fold =  ', k+1, ', acc = ', acc[k])\n        k += 1\n\n      cv_results['mean_acc'].append(round(acc.mean(), 3))\n      cv_results['std_acc'].append(round(acc.std(), 3))\n      cv_results['mean_kappa'].append(round(kappa.mean(), 3))\n      cv_results['std_kappa'].append(round(kappa.std(), 3))\n      cv_results['mean_auc'].append(round(auc.mean(), 3))\n      cv_results['std_auc'].append(round(auc.std(), 3))\n\n    best_score = max(cv_results['mean_acc'])\n    index = [idx for idx, val in enumerate(cv_results['mean_acc']) if val == best_score]\n    if len(index) == 1:\n      best_index = index[0]\n    else:\n      min_std =  cv_results['std_acc'][index[0]]\n      best_index = index[0]\n      for idx in index[1:]:\n        if min_std > cv_results['std_acc'][idx]:\n          min_std = cv_results['std_acc'][idx]\n          best_index = idx\n        \n    cv_results['best_index'] = best_index\n            \n    print('best param = ', cv_results['params'][cv_results['best_index']], ', best_score = ', best_score)\n\n    #refit\n\n    batch_size, C, T = X_train.shape[:-1]\n\n    clear_session()\n    set_seed(seed)\n\n    model = get_model(**model_args, number_of_channels = C, number_of_time_samples = T)\n    model.compile(loss = compile_args['loss'],\n                  loss_weights = [1 - cv_results['params'][cv_results['best_index']], cv_results['params'][cv_results['best_index']]],\n                  optimizer = Adam(compile_args['init_lr']))\n    \n    history = model.fit(X, [y, y],\n              batch_size = batch_size,\n              **fit_args)\n\n    model.save_weights('sbj' + str(load_args['sbj']) +'.h5')\n\n    return cv_results","metadata":{"id":"Ma9-O4lXcy31","execution":{"iopub.status.busy":"2024-07-23T14:12:35.221083Z","iopub.execute_input":"2024-07-23T14:12:35.221729Z","iopub.status.idle":"2024-07-23T14:12:35.254717Z","shell.execute_reply.started":"2024-07-23T14:12:35.221683Z","shell.execute_reply":"2024-07-23T14:12:35.253674Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from pickle import dump\n\nsubjects = np.arange(db.metadata['subjects']) + 1\nsubjects = np.delete(subjects, [28,33])\n\nfor sbj in subjects[40:]:\n    load_args['sbj'] = sbj\n    results = train(load_args, cv_args, model_args, compile_args, fit_args, seed)\n    with open('sbj' + str(load_args['sbj']) + '.txt', 'wb') as f:\n        dump(results, f)","metadata":{"id":"NCYPLxf6zN4B","outputId":"8b843911-2f14-453e-e26f-c454b847a430","execution":{"iopub.status.busy":"2024-07-23T14:12:36.335033Z","iopub.execute_input":"2024-07-23T14:12:36.335733Z","iopub.status.idle":"2024-07-23T14:36:20.828285Z","shell.execute_reply.started":"2024-07-23T14:12:36.335680Z","shell.execute_reply":"2024-07-23T14:36:20.827386Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!zip Models.zip ./*.h5\n!zip Results.zip ./*.txt","metadata":{"id":"kzbo0qEM5vki","outputId":"4ea55661-6500-4bac-8c11-1018f2be75b8","execution":{"iopub.status.busy":"2024-07-23T14:09:51.064625Z","iopub.status.idle":"2024-07-23T14:09:51.065012Z","shell.execute_reply.started":"2024-07-23T14:09:51.064829Z","shell.execute_reply":"2024-07-23T14:09:51.064846Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}